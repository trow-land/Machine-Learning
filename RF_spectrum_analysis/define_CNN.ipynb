{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93748a10-48f6-403b-927f-dd7f9cda029c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7368eb97-08ef-4ca7-8550-23a3387f0c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cbb199-ac64-4f19-80a4-16d097fe8680",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\tom_r\\Desktop\\Machine-Learning\\RF_spectrum_analysis\\subset.pkl\", 'rb') as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6149b09-7d51-4296-9f1f-de891a0aaf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: shape (532480, 1024, 2), dtype float16\n",
      "y: shape (532480,), dtype int64\n",
      "snr: shape (532480,), dtype int64\n"
     ]
    }
   ],
   "source": [
    "for k, v in dataset.items():\n",
    "    print(f\"{k}: shape {v.shape}, dtype {v.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96931f78-8a56-417f-b177-80b43e6a1d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(dataset['y'])\n",
    "label_map = {old: new for new, old in enumerate(unique_labels)}\n",
    "\n",
    "# Remap y labels\n",
    "mapped_y = np.vectorize(label_map.get)(dataset['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b01b8f-9dc6-4807-9c9d-cc19c9688dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], shape=(532480,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804eacd7-6c48-4f86-ae07-ee506c4eb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(dataset['X'], dtype=torch.float32)  \n",
    "X_tensor = X_tensor.permute(0, 2, 1)  # (N, 2, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae205db3-eb6c-4fbd-b59b-4e059b380323",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv1d(in_channels=2, out_channels=16, kernel_size=3)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(16)\n",
    "        self.conv_layer2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        self.max_pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv_layer3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        self.conv_layer4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(128)\n",
    "        self.max_pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(32384, 128)\n",
    "        self.dropout = nn.Dropout(p=0.5) \n",
    "        self.fc2 = nn.Linear(128, 5)  # 5 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv_layer3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv_layer4(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)      \n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22de087c-0b88-40c5-8f4f-ffb2ebdf3d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32384])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = CNN()\n",
    "output = m.forward(X_tensor[0].unsqueeze(0))  # now shape: (1, 2, 1024)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8e44730-a9e2-46aa-af43-316ddf9c87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).permute(0, 2, 1)  # (N, 2, 1024)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90013ce6-b0e7-49a6-b921-b497e006ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dataset = RFDataset(dataset['X'], mapped_y)\n",
    "rf_loader = DataLoader(rf_dataset, batch_size=254, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6345105b-f213-4194-b2fe-ff24fd2f57d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0002) tensor(0.7070)\n"
     ]
    }
   ],
   "source": [
    "for batch_X, _ in rf_loader:\n",
    "    print(batch_X.mean(), batch_X.std())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdffda4a-0134-4a64-aeef-9b13fb5a0270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8320"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate steps per epoch for training\n",
    "trainSteps = len(rf_loader.dataset) // 64\n",
    "trainSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4b34c6e-727c-4548-a726-7088cdace8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/2097], Loss: 1.0895\n",
      "Epoch [1/5], Step [200/2097], Loss: 0.8228\n",
      "Epoch [1/5], Step [300/2097], Loss: 0.8251\n",
      "Epoch [1/5], Step [400/2097], Loss: 0.7457\n",
      "Epoch [1/5], Step [500/2097], Loss: 0.6581\n",
      "Epoch [1/5], Step [600/2097], Loss: 0.6798\n",
      "Epoch [1/5], Step [700/2097], Loss: 0.7023\n",
      "Epoch [1/5], Step [800/2097], Loss: 0.6407\n",
      "Epoch [1/5], Step [900/2097], Loss: 0.6100\n",
      "Epoch [1/5], Step [1000/2097], Loss: 0.6470\n",
      "Epoch [1/5], Step [1100/2097], Loss: 0.6483\n",
      "Epoch [1/5], Step [1200/2097], Loss: 0.5374\n",
      "Epoch [1/5], Step [1300/2097], Loss: 0.5570\n",
      "Epoch [1/5], Step [1400/2097], Loss: 0.6118\n",
      "Epoch [1/5], Step [1500/2097], Loss: 0.6180\n",
      "Epoch [1/5], Step [1600/2097], Loss: 0.5264\n",
      "Epoch [1/5], Step [1700/2097], Loss: 0.5624\n",
      "Epoch [1/5], Step [1800/2097], Loss: 0.5452\n",
      "Epoch [1/5], Step [1900/2097], Loss: 0.6152\n",
      "Epoch [1/5], Step [2000/2097], Loss: 0.6532\n",
      "Epoch 1 finished → Avg Loss: 0.6798, Accuracy: 69.14%\n",
      "Epoch [2/5], Step [100/2097], Loss: 0.5906\n",
      "Epoch [2/5], Step [200/2097], Loss: 0.5216\n",
      "Epoch [2/5], Step [300/2097], Loss: 0.5171\n",
      "Epoch [2/5], Step [400/2097], Loss: 0.5464\n",
      "Epoch [2/5], Step [500/2097], Loss: 0.5560\n",
      "Epoch [2/5], Step [600/2097], Loss: 0.4959\n",
      "Epoch [2/5], Step [700/2097], Loss: 0.6162\n",
      "Epoch [2/5], Step [800/2097], Loss: 0.5195\n",
      "Epoch [2/5], Step [900/2097], Loss: 0.5640\n",
      "Epoch [2/5], Step [1000/2097], Loss: 0.4955\n",
      "Epoch [2/5], Step [1100/2097], Loss: 0.5217\n",
      "Epoch [2/5], Step [1200/2097], Loss: 0.5433\n",
      "Epoch [2/5], Step [1300/2097], Loss: 0.5151\n",
      "Epoch [2/5], Step [1400/2097], Loss: 0.5876\n",
      "Epoch [2/5], Step [1500/2097], Loss: 0.3844\n",
      "Epoch [2/5], Step [1600/2097], Loss: 0.5633\n",
      "Epoch [2/5], Step [1700/2097], Loss: 0.5040\n",
      "Epoch [2/5], Step [1800/2097], Loss: 0.5629\n",
      "Epoch [2/5], Step [1900/2097], Loss: 0.4885\n",
      "Epoch [2/5], Step [2000/2097], Loss: 0.4633\n",
      "Epoch 2 finished → Avg Loss: 0.5472, Accuracy: 74.39%\n",
      "Epoch [3/5], Step [100/2097], Loss: 0.5606\n",
      "Epoch [3/5], Step [200/2097], Loss: 0.5188\n",
      "Epoch [3/5], Step [300/2097], Loss: 0.5743\n",
      "Epoch [3/5], Step [400/2097], Loss: 0.5035\n",
      "Epoch [3/5], Step [500/2097], Loss: 0.4917\n",
      "Epoch [3/5], Step [600/2097], Loss: 0.5597\n",
      "Epoch [3/5], Step [700/2097], Loss: 0.5799\n",
      "Epoch [3/5], Step [800/2097], Loss: 0.5399\n",
      "Epoch [3/5], Step [900/2097], Loss: 0.5405\n",
      "Epoch [3/5], Step [1000/2097], Loss: 0.4904\n",
      "Epoch [3/5], Step [1100/2097], Loss: 0.4739\n",
      "Epoch [3/5], Step [1200/2097], Loss: 0.4939\n",
      "Epoch [3/5], Step [1300/2097], Loss: 0.5470\n",
      "Epoch [3/5], Step [1400/2097], Loss: 0.5096\n",
      "Epoch [3/5], Step [1500/2097], Loss: 0.4121\n",
      "Epoch [3/5], Step [1600/2097], Loss: 0.5132\n",
      "Epoch [3/5], Step [1700/2097], Loss: 0.5108\n",
      "Epoch [3/5], Step [1800/2097], Loss: 0.5173\n",
      "Epoch [3/5], Step [1900/2097], Loss: 0.5699\n",
      "Epoch [3/5], Step [2000/2097], Loss: 0.4770\n",
      "Epoch 3 finished → Avg Loss: 0.5239, Accuracy: 75.39%\n",
      "Epoch [4/5], Step [100/2097], Loss: 0.4050\n",
      "Epoch [4/5], Step [200/2097], Loss: 0.5246\n",
      "Epoch [4/5], Step [300/2097], Loss: 0.4463\n",
      "Epoch [4/5], Step [400/2097], Loss: 0.5648\n",
      "Epoch [4/5], Step [500/2097], Loss: 0.5233\n",
      "Epoch [4/5], Step [600/2097], Loss: 0.5214\n",
      "Epoch [4/5], Step [700/2097], Loss: 0.5261\n",
      "Epoch [4/5], Step [800/2097], Loss: 0.4800\n",
      "Epoch [4/5], Step [900/2097], Loss: 0.5251\n",
      "Epoch [4/5], Step [1000/2097], Loss: 0.5303\n",
      "Epoch [4/5], Step [1100/2097], Loss: 0.4754\n",
      "Epoch [4/5], Step [1200/2097], Loss: 0.5396\n",
      "Epoch [4/5], Step [1300/2097], Loss: 0.3574\n",
      "Epoch [4/5], Step [1400/2097], Loss: 0.4627\n",
      "Epoch [4/5], Step [1500/2097], Loss: 0.5401\n",
      "Epoch [4/5], Step [1600/2097], Loss: 0.5354\n",
      "Epoch [4/5], Step [1700/2097], Loss: 0.5508\n",
      "Epoch [4/5], Step [1800/2097], Loss: 0.5515\n",
      "Epoch [4/5], Step [1900/2097], Loss: 0.4763\n",
      "Epoch [4/5], Step [2000/2097], Loss: 0.5633\n",
      "Epoch 4 finished → Avg Loss: 0.5102, Accuracy: 76.01%\n",
      "Epoch [5/5], Step [100/2097], Loss: 0.4738\n",
      "Epoch [5/5], Step [200/2097], Loss: 0.4504\n",
      "Epoch [5/5], Step [300/2097], Loss: 0.5020\n",
      "Epoch [5/5], Step [400/2097], Loss: 0.4841\n",
      "Epoch [5/5], Step [500/2097], Loss: 0.4961\n",
      "Epoch [5/5], Step [600/2097], Loss: 0.4753\n",
      "Epoch [5/5], Step [700/2097], Loss: 0.4641\n",
      "Epoch [5/5], Step [800/2097], Loss: 0.4730\n",
      "Epoch [5/5], Step [900/2097], Loss: 0.5476\n",
      "Epoch [5/5], Step [1000/2097], Loss: 0.4769\n",
      "Epoch [5/5], Step [1100/2097], Loss: 0.5191\n",
      "Epoch [5/5], Step [1200/2097], Loss: 0.5594\n",
      "Epoch [5/5], Step [1300/2097], Loss: 0.4723\n",
      "Epoch [5/5], Step [1400/2097], Loss: 0.4565\n",
      "Epoch [5/5], Step [1500/2097], Loss: 0.5792\n",
      "Epoch [5/5], Step [1600/2097], Loss: 0.4908\n",
      "Epoch [5/5], Step [1700/2097], Loss: 0.5061\n",
      "Epoch [5/5], Step [1800/2097], Loss: 0.5208\n",
      "Epoch [5/5], Step [1900/2097], Loss: 0.4749\n",
      "Epoch [5/5], Step [2000/2097], Loss: 0.5262\n",
      "Epoch 5 finished → Avg Loss: 0.5017, Accuracy: 76.42%\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 5 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (batch_X, batch_y) in enumerate(rf_loader):\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "\n",
    "        # Print progress every 100 batches\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(rf_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(rf_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1} finished → Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff70a1a-15a4-4c2f-baeb-6ac2e3acda60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
