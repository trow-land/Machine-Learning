{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf485cb-cfcf-4122-93b3-0674b821c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d86ace54-28b6-459b-9757-af002136e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899681c9-d403-4f45-8b61-c85d363e7359",
   "metadata": {},
   "source": [
    "Basic Block: Conv → BN → ReLU → Conv → BN → Add skip → ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212c423d-0342-4916-a29f-50e95fccd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(out_channels)\n",
    "        # add skip\n",
    "        self.downsample = downsample\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ip = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            ip = self.downsample(ip)\n",
    "        x = x + ip # add the skipped input\n",
    "        \n",
    "        x = self.relu2(x)\n",
    "\n",
    "        return x   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47710ff2-ab00-4861-9f53-d82295509529",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\tom_r\\Desktop\\Machine-Learning\\RF_spectrum_analysis\\subset.pkl\", 'rb') as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ffbd83-ca98-4f15-8c34-f24983aa2416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: shape (532480, 1024, 2), dtype float16\n",
      "y: shape (532480,), dtype int64\n",
      "snr: shape (532480,), dtype int64\n"
     ]
    }
   ],
   "source": [
    "for k, v in dataset.items():\n",
    "    print(f\"{k}: shape {v.shape}, dtype {v.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bac2ae-b734-443c-8948-b12c81e17d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(dataset['y'])\n",
    "label_map = {old: new for new, old in enumerate(unique_labels)}\n",
    "\n",
    "# Remap y labels\n",
    "mapped_y = np.vectorize(label_map.get)(dataset['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab76beb-c8a3-4502-98f4-6217bf5da90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(dataset['X'], dtype=torch.float32)  \n",
    "X_tensor = X_tensor.permute(0, 2, 1)  # (N, 2, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0681a024-37da-4acd-9db8-7eeab3a85676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample = nn.Sequential(\n",
    "    nn.Conv1d(in_channels=2, out_channels=64, kernel_size=1, stride=2),\n",
    "    nn.BatchNorm1d(64)\n",
    ")\n",
    "\n",
    "basic = BasicBlock(in_channels=2, out_channels=64, downsample=downsample)\n",
    "\n",
    "\n",
    "output = basic.forward(X_tensor[0].unsqueeze(0)) \n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3676e05f-6e38-4d90-b8d3-36cd1055fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = BasicBlock(2, 64, downsample=nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm1d(64)\n",
    "        ))\n",
    "\n",
    "        self.layer2 = BasicBlock(64, 128, downsample=nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm1d(128)\n",
    "        ))\n",
    "\n",
    "        self.layer3 = BasicBlock(128, 256, downsample=nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm1d(256)\n",
    "        ))\n",
    "\n",
    "        self.layer4 = BasicBlock(256, 512, downsample=nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm1d(512)\n",
    "        ))\n",
    "\n",
    "        #classifier block\n",
    "        self.adppool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(512, 5)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f315297-7efb-42f0-8412-48ee42ed2198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8320"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RFDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).permute(0, 2, 1)  # (N, 2, 1024)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "rf_dataset = RFDataset(dataset['X'], mapped_y)\n",
    "rf_loader = DataLoader(rf_dataset, batch_size=254, shuffle=True)\n",
    "\n",
    "# calculate steps per epoch for training\n",
    "trainSteps = len(rf_loader.dataset) // 64\n",
    "trainSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52b0aabf-0c07-419f-b0da-dccc8402068e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [254, 64], got [254]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m optimizer.zero_grad()\n\u001b[32m     18\u001b[39m outputs = model(batch_X)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m loss = criterion(outputs, batch_y)\n\u001b[32m     20\u001b[39m loss.backward()\n\u001b[32m     21\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1297\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.cross_entropy(\n\u001b[32m   1298\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1299\u001b[39m         target,\n\u001b[32m   1300\u001b[39m         weight=\u001b[38;5;28mself\u001b[39m.weight,\n\u001b[32m   1301\u001b[39m         ignore_index=\u001b[38;5;28mself\u001b[39m.ignore_index,\n\u001b[32m   1302\u001b[39m         reduction=\u001b[38;5;28mself\u001b[39m.reduction,\n\u001b[32m   1303\u001b[39m         label_smoothing=\u001b[38;5;28mself\u001b[39m.label_smoothing,\n\u001b[32m   1304\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._nn.cross_entropy_loss(\n\u001b[32m   3495\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3496\u001b[39m     target,\n\u001b[32m   3497\u001b[39m     weight,\n\u001b[32m   3498\u001b[39m     _Reduction.get_enum(reduction),\n\u001b[32m   3499\u001b[39m     ignore_index,\n\u001b[32m   3500\u001b[39m     label_smoothing,\n\u001b[32m   3501\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected target size [254, 64], got [254]"
     ]
    }
   ],
   "source": [
    "model = ResNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 5 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (batch_X, batch_y) in enumerate(rf_loader):\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "\n",
    "        # Print progress every 100 batches\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(rf_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(rf_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1} finished → Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781dd27-61c6-4cf6-9975-04a94d13b1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7250a-6cf9-433c-b171-f0d31d7c2538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
